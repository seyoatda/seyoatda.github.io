


[{"content":"","date":"2021年7月11日","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"2021年7月11日","externalUrl":null,"permalink":"/life/","section":"Lives","summary":"","title":"Lives","type":"life"},{"content":"仔细想想，现在距离上次写博客已经过去 4 个月了。一方面是自己的惰性导致写作动力不足；另一方面这几个月换了新的工作，也是没有足够的知识积累，毕竟我也是对自己写的东西有基本的要求的。最近在研究 Godot 引擎，打算自己摸索着做一下俯视角的 2D 游戏，在查阅文档途中看到了一位同志写的博客系列挺不错的：link，遂又尝试拾起写博客的习惯。\n现在是 7 月初，也是下半年的开端了，那么也在这里给自己定一个下半年的计划做为指导：\n每月至少输出 3 篇技术博客 对 Godot 研究并做出游戏原型 下半年阅读完 2 本技术书，并写出读书笔记 当然，上面的计划主要还是针对技术方面，而且列得较为宽松，毕竟我也是个老拖延症了。此外对非技术内容的输出我觉得就随心而为吧，希望在新的下半年能够继续努力~~\n","date":"2021年7月11日","externalUrl":null,"permalink":"/life/%E9%87%8D%E5%90%AF%E4%B9%8B%E8%B7%AF/","section":"Lives","summary":"","title":"重启之路","type":"life"},{"content":"","date":"2021年3月28日","externalUrl":null,"permalink":"/poetry/","section":"Poetries","summary":"","title":"Poetries","type":"poetry"},{"content":"","date":"2021年3月28日","externalUrl":null,"permalink":"/poetry/%E6%97%A0%E9%A2%98/","section":"Poetries","summary":"","title":"无题","type":"poetry"},{"content":" 这世界\n大概就是这个样子的吧\n一样的夜晚，一样的歌\n一样的心情\n坠入这无边的夜\n等着世界将我唤醒\n把我的无知\n再次赋给我\n夜晚的人们，思绪往往比在白天更加多愁善感。19 年 3 月写下此诗。觉得后 3 句有些意境在其中。\n","date":"2021年3月28日","externalUrl":null,"permalink":"/poetry/%E5%A4%9C/","section":"Poetries","summary":"","title":"夜","type":"poetry"},{"content":"","date":"2021年3月8日","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":" Python 中的\u0026quot;self\u0026quot;是什么 # 在使用 pycharm 编写 Python 时，自动补全总会把函数定义的第一个参数定义为 self 。遂查，总结如下：\nself 大体上和静态语言如 Java 中的 this 关键字类似，用于指代实例变量。只是在 Python 中需要主动定义在函数的参数中。但是通过实例调用方法时，无须传入 self 参数。 self 不是关键字，只是一种官方推荐写法，也可以写成其他的名称，但是很容易造成误解，所以不推荐。 由上方的知识可知：如果一个函数如果不是定义在类中，那么就不需要定义 self 变量了。即使定义了，也会作为一个普通的参数使用，参考下方的代码：\ndef outer_func(self, val2): print(self, \u0026#34;\\n\u0026#34; + val2) outer_func(\u0026#34;just a common parameter\u0026#34;, \u0026#34;another common parameter\u0026#34;) # 执行结果 # just a common parameter # another common parameter ","date":"2021年3月8日","externalUrl":null,"permalink":"/tech/python-%E4%B8%AD%E7%9A%84-self-%E6%98%AF%E4%BB%80%E4%B9%88/","section":"Teches","summary":"","title":"Python 中的「self」是什么？","type":"tech"},{"content":"","date":"2021年3月8日","externalUrl":null,"permalink":"/tech/","section":"Teches","summary":"","title":"Teches","type":"tech"},{"content":"生活是什么\n","date":"2021年3月8日","externalUrl":null,"permalink":"/about/","section":"","summary":"","title":"关于","type":"page"},{"content":" 站在地下通道入口\n一眼就能看到尽头的地铁站\n我向着它走去\n就像走向我平庸的生活\n继续重蹈覆辙\n我看向人群\n他们平静如水面\n等待被微风吹皱\n或是被一块石子炸起\n那些支离破碎不会留下任何痕迹\n我也是其中一员\n我心知肚明\n2月份某天下班，于体育西路地下通道入口处，抬头一眼能望到地铁站入口。而我不得不顺着人潮走向它。有感，遂作此诗。\n","date":"2021年2月27日","externalUrl":null,"permalink":"/poetry/%E5%9C%B0%E4%B8%8B%E9%80%9A%E9%81%93%E5%85%A5%E5%8F%A3%E5%A4%84%E9%9A%8F%E6%83%B3/","section":"Poetries","summary":"","title":"地下通道入口处随想","type":"poetry"},{"content":" 什么是双重分派 # 什么是分派（dispatch） # 首先我们需要理解「分派」的含义。分派就是将方法调用与对应的具体方法绑定起来。而判断的依据有两点，这两者可称为「宗量」：\n方法的接收者，也就是哪个对象调用了这个方法 方法的参数，调用方法时传递过来的参数 而不同的判断方法也就产生了不同的分派类型：\n静态分派 V.S. 动态分派\n单重分派 V.S. 多重分派\n下面以我的理解简单地总结一下这几个名词的含义：\n静态分派：静态分派在编译期进行，只根据宗量的静态类型进行判断，在编译完成后不会发生改变。也可称为「编译期多态」。\n动态分派：动态分派在运行期进行，根据宗量的动态类型来判断需要调用哪个方法。也称「运行时多态」。\n多重分派：虽然说 multiple 是「多重」的意思，但是实际上也可称为「双重分派」。多重分派就是同时根据两种宗量的类型进行判断。\n单重分派：单重分派就是只根据其中一种宗量进行判断。\n所以其实这两组词是从两个不同的角度来描述分派的类型，并不冲突。\nJava 中的分派机制 # 在网上很多博客说 Java 中是单重分派；也有人说 Java 中实际上是静态双重分派，动态单重分派。下面是我的推论和总结。\nJava 中的重载机制，是静态分派，其根据方法传入参数的静态类型进行判断，而方法的接收者，也直接在编译期就确定。所以是静态的双重分派。\n而重写机制，肯定是动态分派了。但是其只根据方法接收者的动态类型进行判断。并不会根据方法参数的动态类型进行判断。所以是动态的单重分派。\n那如果一个方法同时被重写和重载了呢，那这个方法属于什么分派机制呢？我认为，重写和重载本来就分别是编译期和运行期的多态机制，就是分开进行讨论的，在程序不同生命周期时间段的分派机制直接分开讨论并进行定义就好了。\n访问者模式与伪双重分派 # 虽然说 Java 在编译期表现出了多重分派，但是也只能定性为单重分派语言，而这在设计代码时就会引起一些不便：在调用方法时无法根据参数的动态类型来分派对应的方法。所以我们只能曲线救国，可以通过以下两种方式实现伪动态双重分派。\ninstanceof # 在方法内部可以通过 Java 的 instanceof 关键字来判断对象的动态类型。通过分支选择来进行对应的处理操作。但是这种思路会让处理代码变得十分臃肿，而且违背了「开闭原则」。每次要新增一个被处理类时，就要修改代码新增一个分支进行处理。具体的实现方法很简单，不赘述。\n访问者模式 # 设计模式中的「访问者模式」就是通过利用伪双重分派来实现的。主要思路如下：\n设调用方为「类 A 」，被调用方为「类 B 」。通过反转调用方和被调用方，让类 A 重写方法来调用类 B 的重载方法。通过 this 变量将类 A 的动态类型传递给类 B 的重载方法，实现了伪双重分派。\n在下面这个例子中，我们想让 Player.play() 方法根据 Instrument 的动态类型来分别调用对应的重载方法，从而进行不同的处理：\nclass Player { void play(Instrument instrument) { System.out.println(\u0026#34;instrument notes\u0026#34;); } void play(Violin violin) { System.out.println(\u0026#34;player starts playing violin\u0026#34;); violin.note(); } void play(Piano piano) { System.out.println(\u0026#34;player starts playing piano\u0026#34;); piano.note(); } } class Instrument { void note() { System.out.println(\u0026#34;instrument notes\u0026#34;); } void accept(Player player) { player.play(this); } } class Violin extends Instrument { @Override public void note() { System.out.println(\u0026#34;violin notes\u0026#34;); } @Override public void accept(Player player) { player.play(this); } } class Piano extends Instrument { @Override public void note() { System.out.println(\u0026#34;piano notes\u0026#34;); } @Override public void accept(Player player) { player.play(this); } } public class Main { public static void main(String[] args) { Player player = new Player(); System.out.println(\u0026#34;-------双重分派-------\u0026#34;); Instrument[] instruments = {new Violin(), new Piano()}; for (Instrument instrument : instruments) { instrument.accept(player); } System.out.println(\u0026#34;-------单重分派-------\u0026#34;); for (Instrument instrument : instruments) { player.play(instrument); } } } // 结果 /* -------双重分派------- player starts playing violin violin notes player starts playing piano piano notes -------单重分派------- instrument notes instrument notes */ 从上方的代码运行结果可以得知，在调用重载方法时，不会根据对象的动态类型进行判断，而是根据静态类型判断，只会调用 play(Instrument) 方法。当然，我们在重载 Player 的方法时可以直接调用 Instrument.note() 方法，让编译器去调用子类重写后的方法。\n但是使用双重分派的意义在于， 把具体的处理逻辑放在调用者 Player 类的方法中，减少对 Instrument 的实现类的修改。事实上 Instrument 的子类只需要实现一个 accept(Player) 方法即可。\n访问者模式的出现基本上也就是因为 Java 这类语言的单重分派特性吧。如果是多重分派的语言，就可以直接利用语言特性了。\n参考文章：\n面向对象语言的多分派、单分派、双重分派 What is dispatching in JAVA? ","date":"2020年12月20日","externalUrl":null,"permalink":"/tech/java%E4%B8%AD%E7%9A%84%E5%A4%9A%E9%87%8D%E5%88%86%E6%B4%BE%E4%B8%8E%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/","section":"Teches","summary":"","title":"Java 中的多重分派与访问者模式","type":"tech"},{"content":"","date":"2020年8月1日","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" 1. Kudu的原理 # 1.1 概述 # Kudu是一个类似Hbase的列式存储分布式数据库，它的定位介于hdfs和hbase之间。\nhdfs：使用列式存储，适合OLAP，不支持单条纪录级别的更新操作，随机读写性能差，不适合用来作实时查询。 hbase：可以高效地随机读写，适用OLTP，但是不适用于SQL，且大数据量时读性能较差。 Kudu就是结合了两者的优点，平衡了两者的缺点。从而同时在OLTP和OLAP中都提供较好的性能。这样就无需为了解决以上两者的缺点而搭建两种架构。\n1.2 基本概念 # Table：是一张表，具有全局的主键，一张table可以分为多个段，即tablet。\nTablet：一个tablet是一张表连续的一个段，类似于关系型数据库的partition分区。\nTablet server：存储tablet，并且向客户端提供读取数据的服务。\n对于指定的tablet，有一个server作为leader，基余server作为follower副本。只有leader处理写请求，follower负责和leader同步数据，并且提供读服务。\nMaster：主要用于管理元数据，监听tserver(tablet server)的状态。当client发出请求时，其先对请求做校验，再分配tserver给client进行请求。\n2. Kudu的安装 # 2.1 前置条件 # 以下是官方文档中给出的一些条件：\n硬件 # 至少一个主机来作为Kudu的Master节点，Master节点数必须是奇数，推荐配置1个或者3个。\n至少一个主机来作为tablet节点，如果需要备份复制，那么至少需要3个服务器\n2k个数量的Master节点和2k-1个节点的容错等级是一样的。4个节点和3个节点一样，只能容忍一个错误。2个节点则不能容错。（这也是为什么官方推荐1个或3个节点的原因）\n所以使用1台服务器也可以进行基本的Kudu的安装与运行\n操作系统 # Linux # RHEL / CentOS 6.6+ or Ubuntu 16 18 or Debian 8 ntp服务 xfs/ext4格式的磁盘 Windows # 不支持 磁盘 # 如果能使用SSD，会显著地改善Kudu的延迟 至少50GB以上的磁盘空间，（实测想要完整编译，至少需要90GB以上） Java # JDK8 以上，但是不需要JRE 2.2 源码编译 # Kudu虽然提供了Docker的运行方式，但是官方建议只用于测试和学习，并不推荐在正式环境使用Docker运行。所以最好从源码编译一遍。\n编译需要使用到C++11的编译器（GCC4.8)\n笔者使用的是CentOS7.7，以下基于该系统进行说明。\nCentOS # CentOS 7.0 以上的版本就需要安装Red Hat Developer Toolset包用于获取C++编译器。\n安装依赖\n$ sudo yum install autoconf automake cyrus-sasl-devel cyrus-sasl-gssapi \\ cyrus-sasl-plain flex gcc gcc-c++ gdb git java-1.8.0-openjdk-devel \\ krb5-server krb5-workstation libtool make openssl-devel patch \\ pkgconfig redhat-lsb-core rsync unzip vim-common which 笔者的系统是CentOS 7.7，所以需要安装Toolset。\n$ DTLS_RPM=rhscl-devtoolset-3-epel-6-x86_64-1-2.noarch.rpm $ DTLS_RPM_URL=https://www.softwarecollections.org/repos/rhscl/devtoolset-3/epel-6-x86_64/noarch/${DTLS_RPM} $ wget ${DTLS_RPM_URL} -O ${DTLS_RPM} $ sudo yum install -y scl-utils ${DTLS_RPM} $ sudo yum install -y devtoolset-3-toolchain 官网给出的url已经失效，安装失败。但是经验证，没有安装也能正常编译。猜测是只需要安装了gcc并且版本大于4.8就可以了，可以使用gcc --version命令查看版本。\n$ gcc --version gcc (GCC) 8.3.1 20191121 (Red Hat 8.3.1-5) Copyright (C) 2018 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. 从github仓库中获取源码\n$ git clone https://github.com/apache/kudu 使用build-if-necessary.sh脚本可以构建任何缺失的第三方依赖。需要使用到Python，本文中安装的是python 3.6。\n$ build-support/enable_devtoolset.sh thirdparty/build-if-necessary.sh 然后进行一段漫长的等待过程。\n第4步完成后才能进进正式的编译过程，选择一个除了kudu根目录以外的输出目录，进行编译：\n$ mkdir -p build/release $ cd build/release $ ../../build-support/enable_devtoolset.sh ../../thirdparty/installed/common/bin/cmake -DCMAKE_BUILD_TYPE=release --DNO_TESTS=1 ../.. $ make -j4 --DNO_TEST=1参数的作用是在编译时跳过测试工作的编译，否则编译结果将十分巨大。\n安装时可以使用以下参数来跳过指定的组件：\n-DKUDU_CLIENT_INSTALL=OFF 跳过kudu客户端的安装 -DKUDU_TSERVER_INSTALL=OFF跳过tserver的安装 -DKUDU_MASTER_INSTALL=OFF跳过master的安装 假如某个服务器只作为tserver使用，那么可以跳过master的安装以减少磁盘资源占用并加快安装过程。\n编译过程耗时也十分久。喝上一杯茶🍵慢慢等待。\n完成编译后，构建可执行文件，库文件和头文件。进入上一步编译的输出目录，运行下面的命令进行构建。用DESTDIR=xxx指定自己想要输出的位置，如果不指定则默认输出到/usr/local/目录下面。\nsudo make DESTDIR=/home/kudu install 至此最基本的编译安装就完成啦😊！\n2.3 配置Kudu # 我们可以通过在命令行启动时传递参数来对Kudu进行配置，当参数过多时，也可在启动时使用–-flagfile=\u0026lt;file\u0026gt;参数来引用配置文件。更奇妙地是，在配置文件中还可以通过--flagfile=\u0026lt;file\u0026gt;来再次引用另一个配置文件，这样配置参数就相当灵活。\nMaster和Tablet节点的配置可以放在同一个配置文件中，它们会自动识别哪些是属于自己的配置参数。配置参数的格式为-–flag=xxx ，前缀可以用一个或者二个-都OK。\n2.3.1 配置目录 # 每个节点都需要手动配置目录。\n--fs_wal_dir：用来配置Kudu的写前日志WAL（Write-Ahead Log）的输出目录。\n--fs_metadata_dir：配置Kudu每个tablet的元数据的存放目录\n建议这些目录放在一个高性能的、有高带宽的磁盘上，例如SSD。如果--fs_metadata_dir没有指定，那么元数据会放在WAL的输出目录。\n--fs_data_dirs：指定Kudu用于存放数据块的目录。可以通过,分隔添加多个目录，Kudu会把数据平均地存在这些目录中，如果不指定该参数，也是会把数据块放在WAL的输出目录中。\n--fs_wal_dir和--fs_metadata_dir可以设置为--fs_data_dirs给出的目录列表中的某一个目录，但是不能是任何目录列表中目录的子目录。\n每一个目录都只能被一个Kudu进程使用，所以多个Kudu进程要分别设置属于自己的各种目录。否则启动可能会失败。\n以上是一些最基本的设置，更多关于Master节点的配置可在官方网站查阅：kudu-Master配置项\n2.4 部署实战 # 现在有5台服务器资源，经考虑，部署1个Master节点，3个Tablet节点。部署情况如下：\n服务器IP 内存 磁盘 部署服务 120.40.185.* 16GB ESSD 云盘100GB ESSD 云盘500GB Kudu Tablet 116.62.161.* 16GB ESSD 云盘100GB ESSD 云盘500GB Kudu Tablet 121.41.10.* 16GB ESSD 云盘100GB ESSD 云盘500GB Kudu Tablet 112.124.30.* 16GB ESSD 云盘100GB ESSD 云盘100GB Kudu Master 2.4.1 基本过程 # 先分别在四台机上安装Kudu，由于每台服务器只提供一个Master或Tablet节点，所以在安装时可以跳过不需要的部分，这样可以减少对系统资源的占用。安装过程参考上文。\n在安装完之后，分别编写配置文件：\n# tserver配置 --fs_wal_dir=/home/kudu/kudu_data/tserver/wal --fs_data_dirs=/home/kudu/kudu_data/tserver/data --fs_metadata_dir=/home/kudu/kudu_data/tserver/metadata --log_dir=/home/kudu/kudu_data/tserver/logs --tserver_master_addrs=112.124.30.113:7051 --webserver_doc_root=/home/kudu/kudu/www # master 配置 --fs_wal_dir=/home/kudu/kudu_data/master/wal --fs_data_dirs=/home/kudu/kudu_data/master/data --fs_metadata_dir=/home/kudu/kudu_data/master/metadata --log_dir=/home/kudu/kudu_data/master/logs --webserver_doc_root=/home/kudu/kudu/www --trusted_subnets=0.0.0.0/0 master和tserver的前四个配置是在2.3小节提到的基本配置参数。\n--webserver_doc_root是为了能在8051端口看到Kudu的Master节点的一些详细信息（tserver节点的默认端口是8050）。需要指定静态文件的路径，否则在访问8051会报错：\nStatic pages not available. Configure KUDU_HOME or use the \u0026ndash;webserver_doc_root flag to fix page styling.\n由报错信息可知，也可以通过设置KUDU_HOME环境变量来解决，但是笔者在实践时这一方法失效了，所以采取了第2种方法。同时这个WebUI的访问端口也可以通过–-webserver_port参数来修改。\ntserver节点需要额外配置一个--tserver_master_addrs参数，指定一串master节点地址的数组。用于将tserver连接到mastser节点。\n–trusted_subnets参数设置在master上，为了让master节点能够接受tserver节点的连接请求，这里设为0.0.0.0/0接受所有的ip。当然也可以只单独添加其他节点的ip。\n启动后进入master节点的8051端口，点击Tablet Servers可以看到节点已经连上\n3. 模式设计 # Kudu的表格模型结构和传统关系型数据库的模型类似。但是Kudu表的设计要注意的地方又和这些RDBMS不太一样。在Kudu中建表时要着重关注以下3点：\n列设计 主键设计 分区设计 当然前两点在RDBMS中也经常涉及到。\n3.1 完美的模式 # Kudu的官方网站中介绍了一个完美的模式(Schema)应该满足哪些条件：\n数据的分布情况能够使每个服务器接收的读写请求量都差不多，这样每台服务器的压力都不会太大，也不会太小。这取决于分区的设计。 Tablets能够以可预测的速度平缓地增长，并且读取Tablets的耗时不会发生太大的变化。这也很大程度上受分区的影响。 读取操作只扫描查询所需要的数据。这个条件一方面取决于主键的设计，另一方面也会受通过分区设计进行的分区裁剪的影响。 3.2 列设计 # Kudu支持以下列数据类型：\nBOOL：布尔类型 INT8：8位有符号整数 INT32：32位有符号整数 INT64：64位有符号整数 DATE：32位的天数，以Unix时间戳表示 UNIXTIME_MICROS：64位的毫秒数，以Unix时间戳表示 FLOAT：32位浮点数 DOUBLE：64位浮点数 DECIMAL：固定精度数字类型 VARCHAR：不定长字符串 STRING：UTF-8编码的不限长字符串，最大存储64KB的数据（未压缩） BINARY：二进制数据，最大64KB（未压缩） Kudu是使用列式存储的，所以在设计表的时候，最好能够为每一个列指定最合适的数据类型，而不是一股脑地全部设为STRING或者BINARY之类的。\n","date":"2020年8月1日","externalUrl":null,"permalink":"/tech/kudu-%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97/","section":"Teches","summary":"","title":"Kudu 部署指南","type":"tech"},{"content":"","date":"2020年8月1日","externalUrl":null,"permalink":"/tags/nosql/","section":"Tags","summary":"","title":"Nosql","type":"tags"},{"content":"","date":"2020年8月1日","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2020年8月1日","externalUrl":null,"permalink":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/","section":"Tags","summary":"","title":"大数据","type":"tags"},{"content":"","date":"2020年8月1日","externalUrl":null,"permalink":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/","section":"Categories","summary":"","title":"数据库","type":"categories"},{"content":" 1. 概述 # 一个完整的采集链路的流程如下：\n所以要进行采集链路的部署需要以下几个步聚：\nnginx的配置 filebeat部署 logstash部署 kafka部署 kudu部署 下面将详细说明各个部分的部署方法，以及一些基本的配置参数。\n2. 部署流程 # nginx # 1. 安装 # nginx安装直接去官网下载一个压缩文件解压然后用sbin/nginx运行就可以了。\n2. 配置 # 2.1 日志输出格式 # nginx是采集链路的第一个环节，后面的日志采集系统是通过采集nginx日志进行分析的。本节主要对nginx的日志处理的配置进行描述。\n对nginx.conf文件进行配置：\nlog_format log_json escape=json \u0026#39;{ \u0026#34;@timestamp\u0026#34;: \u0026#34;$time_local\u0026#34;, \u0026#39; \u0026#39;\u0026#34;remote_addr\u0026#34;: \u0026#34;$remote_addr\u0026#34;, \u0026#39; \u0026#39;\u0026#34;referer\u0026#34;: \u0026#34;$http_referer\u0026#34;, \u0026#39; \u0026#39;\u0026#34;project\u0026#34;: \u0026#34;$arg_project\u0026#34;, \u0026#39; \u0026#39;\u0026#34;request\u0026#34;: \u0026#34;$request\u0026#34;, \u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status, \u0026#39; \u0026#39;\u0026#34;bytes\u0026#34;: $body_bytes_sent, \u0026#39; \u0026#39;\u0026#34;request_body\u0026#34;: \u0026#34;$request_body\u0026#34;,\u0026#39; \u0026#39;\u0026#34;data\u0026#34;: \u0026#34;$arg_data\u0026#34;,\u0026#39; \u0026#39;\u0026#34;cookies\u0026#34;: \u0026#34;$http_cookie\u0026#34;\u0026#39; \u0026#39; }\u0026#39;; 上面的代码定义了一个nginx的日志输出格式并命名为log_json，并且使用escape=json参数来把变量中可能包含的json字符串自动转义。\n这个日志输出哪些变量都可以灵活配置，取决于采集框架怎么进行数据解析。在本文中，前端发送的请求中，埋点数据可能出现在request body中，也可能出现在url参数中以data=xxx的形式转递，所以将这两个变量打印到日志中。\n输出格式也可以灵活配置，在logstash的输入解析中进行对应的调整就可以了。使用json格式可以直接用json插件进行解析，否则可能就要用grok插件自己写正则进行解析了。这里推荐输出为json格式。\n2.2 监听配置 # ... http { ... server { listen 2346; access_log logs/data_tracking/access.log log_json; location / { error_page 405 =200 $request_uri; } } } 配置监听埋点端口，将请求日志打印到单独的一个文件夹中避免和其他日志混淆，并指定输出格式为上一节配置好的log_json。\n同时把根请求的405代码转发为200，因为请求监听的端口并没有任何资源，请求会返回status_code = 405。\nfilebeat # filebeat是一款开源的轻量级日志采集工具，主要用于整合各个路径下的各种不同的日志文件，并且统一输出到指定的输出点。\n对于filebeat的配置较为简单，而filebeat提供的功能也十分有限，只能进行简单的日志采集工作，所以需要和logstash配和使用\n1. 安装 # 可以直接在官网下载rpm或deb包：\nhttps://www.elastic.co/cn/downloads/beats/filebeat\n下载后直接使用yum localinstall {pacakgeName}进行安装。\n或者使用包管理软件如 apt 和 yum 进行安装：\n首先引入公有签名key\nsudo rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch 然后再添加一个repo文件到/etc/yum.repos.d/目录中\n[elastic-7.x] name=Elastic repository for 7.x packages baseurl=https://artifacts.elastic.co/packages/7.x/yum gpgcheck=1 gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch enabled=1 autorefresh=1 type=rpm-md 最后使用yum命令直接安装即可。\n2. 配置和启动 # filebeat默认安装在/usr/share/filebeat下\nfilebeat目录结构说明：\nhome 安装的根目录 bin 一些二进制执行文件 config 配置文件 data 持久化的数据文件 logs filebeat运行日志 在运行filebeat前，需要对filebeat的一些运行参数进行配置。\n首先需要在filebeat根目录下新建一个filebeat.yml配置文件，并在其中写入如下的内容：\nfilebeat.inputs: - type: log enabled: true paths: - /var/log/*.log output.logstash: hosts:[\u0026#34;localhost:5044\u0026#34;] 注意：所有的横线后都要空一格，不能直接跟字符串。这是YAML的语法格式，可以去了解一下。\nfilebeat.inputs指定了输入的配置。其中type指定了输入的类型是日志类型。paths指定了输入文件的路径，表示读取/var/log/路径下的所有.log结尾的文件。\noutput.logstash指定了输出到logstash的配置。其中hosts可以指定一个数组，写入多个输出地址。\n设置开机启动filebeat\nsystemctl enable filebeat 通过bin/filebeat文件启动filebeat用:\nbin/filebeat -e -c filebeat.yml 3. 和nginx的配合 # 首先修改filebeat.yml中的paths，指定输入为nginx埋点日志的输出位置。\n使用include_lines，指定正则表达式来过滤不符合要求的行。\nnginx日志输出格式是一个请求一行。否则进行单行过滤的时候会有大问题。\n输出配置最好指定为内网ip。\nfilebeat: inputs: - type: log enabled: true paths: - /usr/local/openresty/nginx/logs/data_tracking/access.log* include_lines: [\u0026#39;\u0026#34;project\u0026#34;: \u0026#34;test_bank_event\u0026#34;\u0026#39;] output.logstash: hosts: [\u0026#34;192.168.0.34:5055\u0026#34;] logstash # logstash相对于filebeat并没有那么轻量，但相对来说有更多的功能和数据处理功能。所以一般将filebeat和logstash结合使用。用filebeat读取日志文件并输出到logstash中，再进行后续的数据处理。\n1. 安装 # logstash的安装方法和filebeat的安装基本相同，可以在官网下载安装包进行安装，在此不再赘述。\nhttps://www.elastic.co/cn/downloads/logstash\n2. 配置和启动 # logstash 的默认安装路径也位于/usr/share/目录下。\n其启动文件是安装根目录下的bin/logstash，对于一些简单的配置信息，可以直接以命令行参数的形式指定：\nbin/logstash -e \u0026#39;input { stdin {}} output{ stdout{}}\u0026#39; 这行命令指定了最基本的input和output为标准输入和标准输出。启动后直接在命令行输入内容，回车后就可以看到结构化处理后的数据输出：\nhello world /usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/awesome_print-1.7.0/lib/awesome_print/formatters/base_formatter.rb:31: warning: constant ::Fixnum is deprecated { \u0026#34;@timestamp\u0026#34; =\u0026gt; 2020-06-08T03:38:04.658Z, \u0026#34;host\u0026#34; =\u0026gt; \u0026#34;hadoop\u0026#34;, \u0026#34;message\u0026#34; =\u0026gt; \u0026#34;hello world\u0026#34;, \u0026#34;@version\u0026#34; =\u0026gt; \u0026#34;1\u0026#34; } 要进行更多的配置，最好在安装根目录下新建一个 .conf格式的配置文件。\n要将logstash和filebeat联合使用，需要让logstash接受一个beats格式的输入：\ninput{ beats{ port =\u0026gt; \u0026#34;5044\u0026#34; } } # filter{ # # } output { stdout { codec =\u0026gt; rubydebug} } 上述配置指定了一个beats类型的input，并设置端口为5044\n在写好配置文件后可以使用下面的命令对配置进行检查，其中-f指定了要加载的配置文件：\nbin/logstash -f first-pipeline.conf --config.test_and_exit --config.test_and_exit命令会加载配置文件并检查是否有错误，并在输出检查结果后自动退出。\n如果检查通过，那么就可以启动logstash了：\nbin/logstash -f first-pipeline.conf --config.reload.automatic --config.reload.automatic命令开启了自动重载配置的功能，所以在修改完配置文件后可以不用重启服务，logstash会自动加载更新后的配置。\n如果在filebeat中配置的输出地址和logstash中的输入beats地址相同，那么在启动了这两个服务后，logstash就可以收到filebeat读取到的日志内容。其基本格式和上文中从标准输入获取数据并输出的格式类似。\n3. 和filebeat的配合 # 在输入配置了对应的filebeat的端口后，接下来主要是配置filter模块对日志进行解析，这部分也要根据nginx日志的结构进行灵活的配置。filebeat主要用来收集数据传输给logstash，当然filebeat中也可以进行一些简单的数据处理，但还是推荐filebeat只负责收集日志，发送到logstash进行统一处理。\n下面是一份logstash的conf文件用于参考：\nfilter{ # 首先对filebeat中的数据进行解析，其中\u0026#39;message\u0026#39;对应的值才是我们真正要解析的埋点数据 # 其他还有很多filebeat自动生成的数据。 # 这里使用json插件进行解析，解析完后就可以删除原来的变量了，减少不必要的数据传输 json{ source =\u0026gt; \u0026#34;message\u0026#34; remove_field =\u0026gt; [\u0026#34;message\u0026#34;] } # 对埋点数据进行url解码，因为埋点数据可能是通过url传输的，可能会有进行过url编码 urldecode{ all_fields =\u0026gt; true } # 使用ruby进行base64解码，目标是\u0026#39;data\u0026#39;变量，结果赋值给新建的\u0026#39;b64_decoded\u0026#39;变量。 ruby { init =\u0026gt; \u0026#34;require \u0026#39;base64\u0026#39;\u0026#34; code =\u0026gt; \u0026#34;event.set(\u0026#39;b64_decoded\u0026#39;, Base64.decode64(event.get(\u0026#39;data\u0026#39;))) if event.include?(\u0026#39;data\u0026#39;)\u0026#34; #这里解码出刚刚截取出来的msg字段 remove_field =\u0026gt; [\u0026#34;data\u0026#34;,\u0026#34;request\u0026#34;] } # 在解码后再进行一次json解析，把json字符串转换为json结构体 json { source =\u0026gt; \u0026#34;b64_decoded\u0026#34; remove_field =\u0026gt; [\u0026#34;b64_decoded\u0026#34;] } } 4. 和kafka的配合 # 由于本链路使用的存储为kudu数据库，而logstash是不支持直接写入kudu的；并且要考虑到并发处理和容错，所以要先将数据写入kafka消息队列，再由kafka写入kudu。\n主要是配置conf文件中的output模块：\noutput{ kafka { # 输出为json格式 codec =\u0026gt; json # 指定topic为\u0026#39;test_event\u0026#39; topic_id =\u0026gt; \u0026#34;test_event\u0026#34; } } 必要的配置就只有topic_id，更多的配置参考logstash官方文档对kafka插件的介绍。\n​\n","date":"2020年6月18日","externalUrl":null,"permalink":"/tech/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E9%93%BE%E8%B7%AF%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97/","section":"Teches","summary":"","title":"日志采集链路部署指南","type":"tech"},{"content":" 什么是双重分派 # 什么是分派（dispatch） # 首先我们需要理解「分派」的含义。分派就是将方法调用与对应的具体方法绑定起来。而判断的依据有两点，这两者可称为「宗量」：\n方法的接收者，也就是哪个对象调用了这个方法 方法的参数，调用方法时传递过来的参数 而不同的判断方法也就产生了不同的分派类型：\n静态分派 V.S. 动态分派\n单重分派 V.S. 多重分派\n下面以我的理解简单地总结一下这几个名词的含义\n静态分派 # 静态分派在编译期进行，只根据宗量的静态类型进行判断，在编译完成后不会发生改变。也可称为「编译期多态」\n动态分派 # 动态分派在运行期进行，根据宗量的动态类型来判断需要调用哪个方法。也称「运行时多态」。\n多重分派 # 多重分派就是同时根据两种宗量的类型进行判断。单重分派就是只根据其中一种宗量进行判断。所以其实这两组词是从两个不同的角度来描述分派的类型，并不冲突。\n虽然说 multiple 是「多重」的意思，但是实际上也可称为「双重分派」。\nJava 中的分派机制 # 在网上很多博客说 Java 中是单重分派；也有人说 Java 中实际上是静态双重分派，动态单重分派。下面是我的推论和总结。\nJava 中的重载机制，是静态分派，其根据方法传入参数的静态类型进行判断，而方法的接收者，也直接在编译期就确定。所以是静态的双重分派。\n而重写机制，肯定是动态分派了。但是其只根据方法接收者的动态类型进行判断。并不会根据方法参数的动态类型进行判断。所以是动态的单重分派。\n那如果一个方法同时被重写和重载了呢，那这个方法属于什么分派机制呢？我认为，重写和重载本来就分别是编译期和运行期的多态机制，就是分开进行讨论的，在程序不同生命周期时间段的分派机制直接分开讨论并进行定义就好了。\n访问者模式与伪双重分派 # 虽然说 Java 在编译期表现出了多重分派，但是也只能定性为单重分派语言，而这在设计代码时就会引起一些不便：在调用方法时无法根据参数的动态类型来分派对应的方法。所以我们只能曲线救国，可以通过以下两种方式实现伪动态双重分派。\n1. instanceof # 在方法内部可以通过 Java 的 instanceof 关键字来判断对象的动态类型。通过分支选择来进行对应的处理操作。但是这种思路会让处理代码变得十分臃肿，而且违背了「开闭原则」。每次要新增一个被处理类时，就要修改代码新增一个分支进行处理。具体的实现方法很简单，不赘述。\n2. 访问者模式 # 设计模式中的「访问者模式」就是通过利用伪双重分派来实现的。主要思路如下：\n设调用方为「类 A 」，被调用方为「类 B 」。通过反转调用方和被调用方，让类 A 重写方法来调用类 B 的重载方法。通过 this 变量将类 A 的动态类型传递给类 B 的重载方法，实现了伪双重分派。\n在下面这个例子中，我们想让 Player.play() 方法根据 Instrument 的动态类型来分别调用对应的重载方法，从而进行不同的处理：\nclass Player { void play(Instrument instrument) { System.out.println(\u0026#34;instrument notes\u0026#34;); } void play(Violin violin) { System.out.println(\u0026#34;player starts playing violin\u0026#34;); violin.note(); } void play(Piano piano) { System.out.println(\u0026#34;player starts playing piano\u0026#34;); piano.note(); } } class Instrument { void note() { System.out.println(\u0026#34;instrument notes\u0026#34;); } void accept(Player player) { player.play(this); } } class Violin extends Instrument { @Override public void note() { System.out.println(\u0026#34;violin notes\u0026#34;); } @Override public void accept(Player player) { player.play(this); } } class Piano extends Instrument { @Override public void note() { System.out.println(\u0026#34;piano notes\u0026#34;); } @Override public void accept(Player player) { player.play(this); } } public class Main { public static void main(String[] args) { Player player = new Player(); System.out.println(\u0026#34;-------双重分派-------\u0026#34;); Instrument[] instruments = {new Violin(), new Piano()}; for (Instrument instrument : instruments) { instrument.accept(player); } System.out.println(\u0026#34;-------单重分派-------\u0026#34;); for (Instrument instrument : instruments) { player.play(instrument); } } } // 结果 /* -------双重分派------- player starts playing violin violin notes player starts playing piano piano notes -------单重分派------- instrument notes instrument notes */ 从上方的代码运行结果可以得知，在调用重载方法时，不会根据对象的动态类型进行判断，而是根据静态类型判断，只会调用 play(Instrument) 方法。当然，我们在重载 Player 的方法时可以直接调用 Instrument.note() 方法，让编译器去调用子类重写后的方法。\n但是使用双重分派的意义在于，把具体的处理逻辑放在调用者 Player 类的方法中，减少对 Instrument 的实现类的修改。事实上 Instrument 的子类只需要实现一个 accept(Player) 方法即可。\n访问者模式的出现基本上也就是因为 Java 这类语言的单重分派特性吧。如果是多重分派的语言，就可以直接利用语言特性了。\n参考文章：\n面向对象语言的多分派、单分派、双重分派\nhttps://www.cnblogs.com/youxin/archive/2013/05/25/3099016.html\nWhat is dispatching in JAVA?\nhttps://stackoverflow.com/questions/5508274/what-is-dispatching-in-java\n","externalUrl":null,"permalink":"/life/untitled/","section":"Lives","summary":"","title":"","type":"life"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]